{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def fill_na(mat):\n",
    "    ix,iy = np.where(np.isnan(mat))\n",
    "    for i,j in zip(ix,iy):\n",
    "        if np.isnan(mat[i+1,j]):\n",
    "            mat[i,j]=mat[i-1,j]\n",
    "        else:\n",
    "            mat[i,j]=(mat[i-1,j]+mat[i+1,j])/2.\n",
    "    return mat\n",
    "\n",
    "\n",
    "def read_temps(path):\n",
    "    \"\"\"Lit le fichier de températures\"\"\"\n",
    "    data = []\n",
    "    with open(path, \"rt\") as fp:\n",
    "        reader = csv.reader(fp, delimiter=',')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            if not row[1].replace(\".\",\"\").isdigit():\n",
    "                continue\n",
    "            data.append([float(x) if x != \"\" else float('nan') for x in row[1:]])\n",
    "    return torch.tensor(fill_na(np.array(data)), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    #  TODO:  Implémenter comme décrit dans la question 1\n",
    "    def __init__(self, latent_dim, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.latent_size = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.act_encode = torch.tanh\n",
    "        self.act_decode = torch.tanh\n",
    "\n",
    "        # Network parameters\n",
    "        self.linearX = nn.Linear(input_dim, latent_dim, bias=True)\n",
    "        self.linearH = nn.Linear(latent_dim, latent_dim, bias=False)\n",
    "        \n",
    "        self.linearD = nn.Linear(latent_dim, output_dim, bias=True)\n",
    "        \n",
    "\n",
    "    def one_step(self, x, h):\n",
    "        \"\"\" \n",
    "        compute the hidden state for one step of time\n",
    "        dim(x) = batch x dimX\n",
    "        dim(h) = batch x latent_size\n",
    "        \"\"\"\n",
    "        return self.act_encode(self.linearX(x) + self.linearH(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Treat a batch of sequences,\n",
    "        x -> batch of sequences, dim(X) = lenght_sequence x batch x dimX\n",
    "        h -> init hidden state, dim(h) = batch x latent_size\n",
    "\n",
    "        return a batch of hidden state sequences -> dim = lenght_sequence x batch x latent_size\n",
    "        \"\"\"\n",
    "        length, batch, dim = x.shape\n",
    "        res = torch.zeros((length, batch, self.latent_size), dtype=torch.float)\n",
    "        res[0] = self.one_step(x[0], torch.zeros((batch, self.latent_size), dtype=torch.float)) \n",
    "\n",
    "        for i in range(1,length):\n",
    "            res[i] = self.one_step(x[i], res[i-1].clone())\n",
    "\n",
    "        return res\n",
    "\n",
    "        \n",
    "    def decode(self, h):\n",
    "        \"\"\"\n",
    "        decode a batch of hidden state\n",
    "        \"\"\"\n",
    "        return self.act_decode(self.linearD(h))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    #  TODO:  Implémenter comme décrit dans la question 1\n",
    "    def __init__(self, latent_dim, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.latent_size = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.act_encode = torch.tanh\n",
    "        self.act_decode = torch.tanh\n",
    "\n",
    "        # Network parameters\n",
    "        self.linearX = nn.Linear(input_dim, latent_dim, bias=True)\n",
    "        self.linearH = nn.Linear(latent_dim, latent_dim, bias=False)\n",
    "        \n",
    "        self.linearD = nn.Linear(latent_dim, output_dim, bias=True)\n",
    "        \n",
    "\n",
    "    def one_step(self, x, h):\n",
    "        \"\"\" \n",
    "        compute the hidden state for one step of time\n",
    "        dim(x) = batch x dimX\n",
    "        dim(h) = batch x latent_size\n",
    "        \"\"\"\n",
    "        return self.act_encode(self.linearX(x) + self.linearH(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Treat a batch of sequences,\n",
    "        x -> batch of sequences, dim(X) = lenght_sequence x batch x dimX\n",
    "        h -> init hidden state, dim(h) = batch x latent_size\n",
    "\n",
    "        return a batch of hidden state sequences -> dim = lenght_sequence x batch x latent_size\n",
    "        \"\"\"\n",
    "        length, batch, dim = x.shape\n",
    "        res = []\n",
    "        res.append(self.one_step(x[0], torch.zeros((batch, self.latent_size), dtype=torch.float)))\n",
    "\n",
    "        for i in range(1,length):\n",
    "            res.append(self.one_step(x[i], res[i-1]))\n",
    "\n",
    "        return torch.stack(res)\n",
    "\n",
    "        \n",
    "    def decode(self, h):\n",
    "        \"\"\"\n",
    "        decode a batch of hidden state\n",
    "        \"\"\"\n",
    "        return self.act_decode(self.linearD(h))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File exo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from utils import read_temps, device, RNN, Dataset_temp\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#  TODO:  Question 2 : prédiction de la ville correspondant à une séquence\n",
    "\n",
    "temp_test, temp_test_labels = read_temps(\"data/tempAMAL_test.csv\").unsqueeze(1), torch.arange(30)\n",
    "temp_train, temp_train_labels = read_temps(\"data/tempAMAL_train.csv\").unsqueeze(1), torch.arange(30)\n",
    "print(f\"train shape {temp_train.shape}\")\n",
    "print(f\"test shape {temp_test.shape}\")\n",
    "\n",
    "import ipdb; ipdb.set_trace()\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "train_loader = DataLoader(Dataset_temp(temp_train, temp_train_labels), shuffle=True, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(Dataset_temp(temp_test, temp_test_labels), shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "latent_size = 20\n",
    "input_dim = 1\n",
    "output_dim = temp_train.shape[1]\n",
    "\n",
    "model = RNN(latent_size, input_dim, output_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[model.Wx,model.Wh,model.Wd,model.bh,model.bd],lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "print(\"Training ...\")\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (sequences, labels) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hidden_states = model(sequences)\n",
    "        outputs = model.decode(hidden_states[-1])\n",
    "        train_loss = error(outputs, sequences)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    for i, (sequences, labels) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            hidden_states = model(sequences)\n",
    "            outputs = model.decode(hidden_states[-1])\n",
    "        test_loss = error(outputs, sequences)\n",
    "        \n",
    "        #writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "  #if(epoch%10==0):\n",
    "    print(f\"Itérations {epoch}: train loss {train_loss}, test loss {test_loss}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_temp(Dataset):\n",
    "    def __init__(self, data, target, lenght=50):\n",
    "        self.data = data\n",
    "        self.lenght = lenght\n",
    "        self.size = self.data.shape[0]-self.lenght+1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        col = index//self.size\n",
    "        lin = index%self.size\n",
    "        return (self.data[lin:lin+self.lenght, col], col)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size*self.data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = read_temps(\"data/tempAMAL_train.csv\").unsqueeze(2)\n",
    "temp_test = read_temps(\"data/tempAMAL_test.csv\").unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClasse = 5\n",
    "longueurData = 30\n",
    "BATCH_SIZE = 6\n",
    "longueurSeq = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = temp_train[:longueurData, :nbClasse]\n",
    "temp_test = temp_test[:longueurData, :nbClasse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Dataset_temp(temp_train, None, longueurSeq), shuffle=True, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(Dataset_temp(temp_test, None, longueurSeq), shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "latent_size = 10\n",
    "input_dim = 1\n",
    "output_dim = nbClasse\n",
    "lr=1e-3\n",
    "\n",
    "model = RNN(latent_size, input_dim, output_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Itérations 0: train loss 1.408150315284729, test loss 1.4691978693008423\n",
      "Itérations 1: train loss 1.2020816802978516, test loss 1.2513796091079712\n",
      "Itérations 2: train loss 2.1629505157470703, test loss 1.7868728637695312\n",
      "Itérations 3: train loss 1.5914438962936401, test loss 1.7306660413742065\n",
      "Itérations 4: train loss 1.6886820793151855, test loss 1.5907374620437622\n",
      "Itérations 5: train loss 1.6217952966690063, test loss 1.6637362241744995\n",
      "Itérations 6: train loss 1.5996265411376953, test loss 1.5807021856307983\n",
      "Itérations 7: train loss 1.6258958578109741, test loss 1.622285008430481\n",
      "Itérations 8: train loss 1.6335803270339966, test loss 1.6276897192001343\n",
      "Itérations 9: train loss 1.597016453742981, test loss 1.5985349416732788\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"Training ...\")\n",
    "\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, (sequences, labels) in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            hidden_states = model(sequences.permute(1,0,2))\n",
    "            outputs = model.decode(hidden_states[-1])\n",
    "            \n",
    "            train_loss = criterion(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "\n",
    "        model.eval()\n",
    "        for i, (sequences, labels) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "\n",
    "                hidden_states = model(sequences.permute(1,0,2))\n",
    "                outputs = model.decode(hidden_states[-1])\n",
    "                test_loss = criterion(outputs, labels)\n",
    "\n",
    "            #writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "      #if(epoch%10==0):\n",
    "        print(f\"Itérations {epoch}: train loss {train_loss}, test loss {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTRES = string.ascii_letters + string.punctuation+string.digits+' '\n",
    "id2lettre = dict(zip(range(1, len(LETTRES)+1), LETTRES))\n",
    "id2lettre[0] = ''\n",
    "lettre2id = dict(zip(id2lettre.values(), id2lettre.keys()))\n",
    "\n",
    "def normalize(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if c in LETTRES)\n",
    "\n",
    "def string2code(s):\n",
    "    return torch.tensor([lettre2id[c] for c in normalize(s)])\n",
    "\n",
    "def code2string(t):\n",
    "    if(type(t)!=list):\n",
    "        t = t.tolist()\n",
    "    return ''.join(id2lettre[i] for i in t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20,  5, 19, 20, 95,  1, 22,  5,  3, 95,  1,  3,  3,  5, 14, 20, 95,  5,\n",
       "         3, 15, 12,  5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2code(\"test avec accent école\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-traitement données trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTrumpData(s):\n",
    "    tmp = re.sub(\"\\[[^]]+\\]\", \"\", s) #delete non vocan words as [applause]\n",
    "    tmp = re.sub(\":\\s*pmurT\\s*\\.\", \":%.\", tmp[::-1]) #reverse string and replace trump by %\n",
    "    tmp = re.sub(\":[^.%]+?\\.\", \":@.\", tmp) # place all no trump speaker by @\n",
    "    tmp = re.sub(\"^\\s*Trump\", \"%\", tmp[::-1]) #reverse string and replace first Trump by %\n",
    "    tmp = re.sub(\"@\\s*:[^%]+?%\", \"%\", tmp)  #delete words not say by trump\n",
    "    return re.sub(\"%:\", \"\", tmp)# delete %: wich is just to show wo speaks (but now it is trump every time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Wow. Whoa. That is some group of people. Thousands. So nice, thank you very much. That's really nice. Thank you. It's great to be at Trump Tower. It's great to be in a wonderful city, New York. And it's an honor to have everybody here. This is beyond anybody's expectations. There's been no crowd like this. And, I can tell, some of the candidates, they went in. They didn't know the air-conditioner didn't work. They sweated like dogs.  They didn't know the room was too big, because they didn't have anybody there. How are they going to beat ISIS? I don't think it's gonna happen.  Our country is in serious trouble. We don't have victories anymore. We used to have victories, but we don't have them. When was the last time anybody saw us beating, let's say, China in a trade deal? They kill us. I beat China all the time. All the time. When did we beat Japan at anything? They send their cars over by the \""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpData = re.sub(\"\\[[^]]+\\]\", \"\", data[:1000])\n",
    "tmpData = tmpData[::-1]\n",
    "tmpData = re.sub(\":\\s*pmurT\\s*\\.\", \":%.\", tmpData)\n",
    "tmpData = re.sub(\":[^.%]+?\\.\", \":@.\", tmpData) \n",
    "tmpData = re.sub(\"^\\s*Trump\", \"%\", tmpData[::-1])  \n",
    "tmpData = re.sub(\"@\\s*:[^%]+?%\", \"%\", tmpData)\n",
    "re.sub(\"%:\", \"\", tmpData)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_trump(Dataset):\n",
    "    def __init__(self, data, target, lenght=50):\n",
    "        self.data = data\n",
    "        self.lenght = lenght\n",
    "        self.size = self.data.shape[0]-self.lenght+1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        col = index//self.size\n",
    "        lin = index%self.size\n",
    "        return (self.data[lin:lin+self.lenght, col], col)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size*self.data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/trump_full_speech.txt\", 'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = cleanTrumpData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedNormalizedData = normalize(cleanedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = cleanedNormalizedData.replace(\"!\",\".\").replace(\"?\",\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [phrase.strip() for phrase in allData.split(\".\")]\n",
    "phrases = [phrase for phrase in phrases if len(phrase)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" \"Yeah\n",
      "I would\n",
      "So true\n",
      "history\n",
      "Oh, Jon\n",
      "history\n",
      "650,000\n",
      "In cash\n",
      "Chicago\n",
      "Go vote\n",
      "Go vote\n",
      "Go vote\n",
      "Go vote\n"
     ]
    }
   ],
   "source": [
    "for phrase in phrases:\n",
    "    if(len(phrase)==7):\n",
    "        print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 62),\n",
       " (2, 8),\n",
       " (3, 8),\n",
       " (4, 7),\n",
       " (5, 11),\n",
       " (6, 13),\n",
       " (7, 13),\n",
       " (8, 16),\n",
       " (9, 80),\n",
       " (10, 25),\n",
       " (11, 42),\n",
       " (12, 59),\n",
       " (13, 55),\n",
       " (14, 35),\n",
       " (15, 60),\n",
       " (16, 68),\n",
       " (17, 67),\n",
       " (18, 52),\n",
       " (19, 75),\n",
       " (20, 65),\n",
       " (21, 63),\n",
       " (22, 63),\n",
       " (23, 60),\n",
       " (24, 61),\n",
       " (25, 51),\n",
       " (26, 54),\n",
       " (27, 54),\n",
       " (28, 61),\n",
       " (29, 68),\n",
       " (30, 71),\n",
       " (31, 63),\n",
       " (32, 57),\n",
       " (33, 60),\n",
       " (34, 62),\n",
       " (35, 56),\n",
       " (36, 58),\n",
       " (37, 36),\n",
       " (38, 36),\n",
       " (39, 57),\n",
       " (40, 53),\n",
       " (41, 56),\n",
       " (42, 33),\n",
       " (43, 50),\n",
       " (44, 56),\n",
       " (45, 56),\n",
       " (46, 52),\n",
       " (47, 36),\n",
       " (48, 49),\n",
       " (49, 40),\n",
       " (50, 47),\n",
       " (51, 45),\n",
       " (52, 41),\n",
       " (53, 30),\n",
       " (54, 31),\n",
       " (55, 23),\n",
       " (56, 55),\n",
       " (57, 40),\n",
       " (58, 38),\n",
       " (59, 50),\n",
       " (60, 35),\n",
       " (61, 37),\n",
       " (62, 40),\n",
       " (63, 22),\n",
       " (64, 40),\n",
       " (65, 33),\n",
       " (66, 25),\n",
       " (67, 37),\n",
       " (68, 35),\n",
       " (69, 30),\n",
       " (70, 35),\n",
       " (71, 32),\n",
       " (72, 37),\n",
       " (73, 37),\n",
       " (74, 28),\n",
       " (75, 17),\n",
       " (76, 26),\n",
       " (77, 26),\n",
       " (78, 38),\n",
       " (79, 22),\n",
       " (80, 33),\n",
       " (81, 30),\n",
       " (82, 40),\n",
       " (83, 31),\n",
       " (84, 17),\n",
       " (85, 28),\n",
       " (86, 35),\n",
       " (87, 32),\n",
       " (88, 22),\n",
       " (89, 33),\n",
       " (90, 26),\n",
       " (91, 41),\n",
       " (92, 17),\n",
       " (93, 26),\n",
       " (94, 28),\n",
       " (95, 29),\n",
       " (96, 21),\n",
       " (97, 26),\n",
       " (98, 20),\n",
       " (99, 28),\n",
       " (100, 20),\n",
       " (101, 25),\n",
       " (102, 25),\n",
       " (103, 13),\n",
       " (104, 18),\n",
       " (105, 18),\n",
       " (106, 24),\n",
       " (107, 22),\n",
       " (108, 21),\n",
       " (109, 22),\n",
       " (110, 17),\n",
       " (111, 21),\n",
       " (112, 17),\n",
       " (113, 17),\n",
       " (114, 20),\n",
       " (115, 16),\n",
       " (116, 18),\n",
       " (117, 23),\n",
       " (118, 20),\n",
       " (119, 16),\n",
       " (120, 25),\n",
       " (121, 20),\n",
       " (122, 18),\n",
       " (123, 17),\n",
       " (124, 12),\n",
       " (125, 22),\n",
       " (126, 24),\n",
       " (127, 10),\n",
       " (128, 15),\n",
       " (129, 16),\n",
       " (130, 12),\n",
       " (131, 21),\n",
       " (132, 14),\n",
       " (133, 17),\n",
       " (134, 6),\n",
       " (135, 13),\n",
       " (136, 13),\n",
       " (137, 17),\n",
       " (138, 12),\n",
       " (139, 11),\n",
       " (140, 12),\n",
       " (141, 11),\n",
       " (142, 7),\n",
       " (143, 12),\n",
       " (144, 11),\n",
       " (145, 11),\n",
       " (146, 7),\n",
       " (147, 5),\n",
       " (148, 9),\n",
       " (149, 12),\n",
       " (150, 11),\n",
       " (151, 10),\n",
       " (152, 9),\n",
       " (153, 10),\n",
       " (154, 9),\n",
       " (155, 9),\n",
       " (156, 7),\n",
       " (157, 9),\n",
       " (158, 3),\n",
       " (159, 11),\n",
       " (160, 10),\n",
       " (161, 6),\n",
       " (162, 10),\n",
       " (163, 8),\n",
       " (164, 7),\n",
       " (165, 7),\n",
       " (166, 4),\n",
       " (167, 5),\n",
       " (168, 4),\n",
       " (169, 10),\n",
       " (170, 6),\n",
       " (171, 7),\n",
       " (172, 5),\n",
       " (173, 10),\n",
       " (174, 8),\n",
       " (175, 4),\n",
       " (176, 7),\n",
       " (177, 8),\n",
       " (178, 7),\n",
       " (180, 2),\n",
       " (181, 3),\n",
       " (182, 5),\n",
       " (183, 4),\n",
       " (184, 3),\n",
       " (185, 5),\n",
       " (186, 8),\n",
       " (187, 4),\n",
       " (188, 5),\n",
       " (189, 3),\n",
       " (190, 9),\n",
       " (191, 5),\n",
       " (192, 7),\n",
       " (193, 4),\n",
       " (194, 2),\n",
       " (195, 4),\n",
       " (196, 6),\n",
       " (197, 2),\n",
       " (198, 2),\n",
       " (199, 4),\n",
       " (200, 2),\n",
       " (201, 5),\n",
       " (202, 4),\n",
       " (204, 1),\n",
       " (207, 6),\n",
       " (208, 4),\n",
       " (209, 2),\n",
       " (211, 1),\n",
       " (212, 2),\n",
       " (213, 5),\n",
       " (214, 3),\n",
       " (215, 2),\n",
       " (216, 4),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 2),\n",
       " (221, 2),\n",
       " (222, 1),\n",
       " (224, 3),\n",
       " (225, 4),\n",
       " (226, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 2),\n",
       " (231, 1),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 2),\n",
       " (241, 1),\n",
       " (242, 1),\n",
       " (243, 1),\n",
       " (244, 2),\n",
       " (245, 2),\n",
       " (247, 3),\n",
       " (248, 3),\n",
       " (249, 1),\n",
       " (251, 2),\n",
       " (252, 1),\n",
       " (253, 1),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (260, 1),\n",
       " (262, 2),\n",
       " (263, 1),\n",
       " (270, 1),\n",
       " (271, 2),\n",
       " (275, 1),\n",
       " (279, 1),\n",
       " (281, 1),\n",
       " (286, 1),\n",
       " (295, 2),\n",
       " (306, 1),\n",
       " (307, 1),\n",
       " (308, 1),\n",
       " (323, 1),\n",
       " (329, 1),\n",
       " (333, 1),\n",
       " (344, 1),\n",
       " (347, 1),\n",
       " (359, 1),\n",
       " (362, 1),\n",
       " (380, 1),\n",
       " (403, 1),\n",
       " (419, 1),\n",
       " (446, 1),\n",
       " (701, 1),\n",
       " (776, 1)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(Counter([len(phrase) for phrase in phrases]).items()), reverse=False, key=lambda e:e[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1), (2, 2), (1, 3)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
